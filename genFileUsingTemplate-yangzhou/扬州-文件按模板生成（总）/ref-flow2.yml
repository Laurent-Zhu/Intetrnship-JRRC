- name: å£°æ˜ç›¸å…³å˜é‡
  code: declared.operations
  args:
    payload:
      llm:
        name: '<context#model>'
        temperature: <context#temperature>
      role_prompt: |-
        <context#role_prompt>
      bot_name: '<context#bot_name>'
      qa_search_size: <context#qa_search_size>
      kl_search_size: <context#kl_search_size>
      history_turns: <context#history_turns>
      standard_term: '<context#standard_term>'
      qa_database_name: <context#qa_database_name>
      knowledge_id_list: <context#knowledge_id_list>
      qa_knowledge_id: '<context#qa_knowledge_id>'

- name: è·å–å†å²è®°å½•
  code: memories.storage0#messages
  sinks:
    context: history
  
- name: åˆ›å»ºæ•°æ®åº“è¡¨
  code: mysql.operations#execute
  args:
    statement: |-
      CREATE TABLE IF NOT EXISTS {context#qa_database_name} (
        id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,  -- å”¯ä¸€æ ‡è¯†
        question TEXT NOT NULL,
        answer TEXT NOT NULL,
        update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP  -- è‡ªåŠ¨æ›´æ–°æ—¶é—´æˆ³
      );
    commit: true
  sinks:
    # context: qa_database_name
    logging: true

- name: ç›´æ¥å›ç­”
  code: sources.execution
  args:
    locals:
      question: "{context#question}"
      qa_database_name: "{context#qa_database_name}"
    source: |-
      question = question.replace('\n', '')
      direct_answer = self.flows.plugin('mysql.operations').execute(context.subs(payload={'statement': 'SELECT answer FROM {qa_database_name} WHERE question = "{question}" LIMIT 1;'}))
      logging.info(f"direct_answer: {direct_answer}")
      if direct_answer and len(direct_answer) > 0:
          text = direct_answer[0]['answer']
          text = text.replace('#', '').replace('*', '')
          lines = [line for line in text.splitlines() if line.strip()]
          text = '\n'.join(lines)  
          res = 1
      else:
          text = ''
          res = 0
      result = {
          "text": text,
          "res": res
      }
      return result
  sinks:
    context: direct_answer
    logging: true


- name: æ‰“å°
  code: reply.operations
  args:
    pending: "{context#direct_answer.text}"

- name: åˆ¤æ–­
  code: logics.case
  args:
    - when: int({context#direct_answer.res}) == 1
      then: 
        - name: åœæ­¢
          code: abort.operations
    - else:
        - name: åˆ¤æ–­è¯­è¨€
          code: sources.execution
          args:
            source: |-
              def main():
                    
                  import re
                  
                  def detect_language(text):
                      """
                      æ£€æµ‹æ–‡æœ¬è¯­è¨€ç±»å‹ï¼šä¸­æ–‡ã€è‹±æ–‡ã€è’™è¯­
                      è¿”å›: 'chinese', 'english', 'mongolian'
                      """
                      if not text or not text.strip():
                          return 'chinese'  # é»˜è®¤ä¸­æ–‡
                      
                      text = text.strip()
                      total_chars = len(text)
                      
                      # ç»Ÿè®¡å„ç§å­—ç¬¦æ•°é‡
                      chinese_chars = 0
                      english_chars = 0
                      mongolian_chars = 0
                      
                      for char in text:
                          # ä¸­æ–‡å­—ç¬¦ (åŒ…æ‹¬æ ‡ç‚¹ç¬¦å·)
                          if '\u4e00' <= char <= '\u9fff' or '\u3400' <= char <= '\u4dbf':
                              chinese_chars += 1
                          # è‹±æ–‡å­—ç¬¦
                          elif char.isalpha() and ord(char) < 128:
                              english_chars += 1
                          # è’™å¤æ–‡å­—ç¬¦ (ä¼ ç»Ÿè’™å¤æ–‡)
                          elif '\u1800' <= char <= '\u18af':
                              mongolian_chars += 1
                          # è’™å¤æ–‡æ‰©å±•å­—ç¬¦
                          elif '\u11ee' <= char <= '\u11f9':
                              mongolian_chars += 1
                      
                      # è®¡ç®—å„è¯­è¨€å­—ç¬¦å æ¯”
                      chinese_ratio = chinese_chars / total_chars if total_chars > 0 else 0
                      english_ratio = english_chars / total_chars if total_chars > 0 else 0
                      mongolian_ratio = mongolian_chars / total_chars if total_chars > 0 else 0
                      
                      # åˆ¤æ–­é€»è¾‘ï¼šä¼˜å…ˆçº§ è’™è¯­ > ä¸­æ–‡ > è‹±æ–‡
                      if mongolian_ratio > 0.1:  # è’™è¯­å­—ç¬¦å æ¯”è¶…è¿‡10%
                          return 'mongolian'
                      elif chinese_ratio > 0.3:  # ä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡30%
                          return 'chinese'
                      elif english_ratio > 0.5:  # è‹±æ–‡å­—ç¬¦å æ¯”è¶…è¿‡50%
                          return 'english'
                      else:
                          # å¦‚æœéƒ½ä¸æ»¡è¶³ï¼ŒæŒ‰æœ€é«˜å æ¯”åˆ¤æ–­
                          max_ratio = max(chinese_ratio, english_ratio, mongolian_ratio)
                          if max_ratio == mongolian_ratio and mongolian_ratio > 0:
                              return 'mongolian'
                          elif max_ratio == chinese_ratio:
                              return 'chinese'
                          elif max_ratio == english_ratio:
                              return 'english'
                          else:
                              return 'chinese'  # é»˜è®¤ä¸­æ–‡
                  
                  # è·å–ç”¨æˆ·è¾“å…¥
                  user_input = "{context#question}"
                  detected_lang = detect_language(user_input)
                  
                  # è¿”å›è¯­è¨€ä¿¡æ¯
                  return detected_lang
              return main()
          sinks:
            context: language_info
            logging: true

        - name: è·å–å½“å‰æ—¶é—´, æ˜ŸæœŸå‡ 
          code: sources.execution
          args:
            source: |-
              from datetime import datetime

              # è·å–å½“å‰æ—¶é—´
              now = datetime.now()
              
              # ä¸­æ–‡æ˜ŸæœŸå‡ æ˜ å°„
              weekday_map = {
                  0: "æ˜ŸæœŸä¸€",
                  1: "æ˜ŸæœŸäºŒ",
                  2: "æ˜ŸæœŸä¸‰",
                  3: "æ˜ŸæœŸå››",
                  4: "æ˜ŸæœŸäº”",
                  5: "æ˜ŸæœŸå…­",
                  6: "æ˜ŸæœŸæ—¥"
              }
              
              # è·å–æ˜ŸæœŸå‡ 
              weekday = weekday_map[now.weekday()]
              return weekday
          sinks:
            context: weekday
            logging: true

        - name: æé—®æ”¹å†™ï¼Œå…³é”®è¯æå– 
          code: llmx.predict.chat
          steps: |-
            { "id": 1, "content": "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..." }
          args:
            messages:
              - type: system
                template: |-
                  ## Role
                  ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„æé—®ï¼Œç»“åˆä¸Šä¸‹æ–‡ç†è§£å…¶çœŸå®æ„å›¾ï¼Œå¹¶å¯¹æé—®è¿›è¡Œä¼˜åŒ–ã€‚

                  ## æ ¸å¿ƒä»»åŠ¡
                  åˆ†æç”¨æˆ·çš„æé—®å’Œå¯¹è¯å†å²ï¼Œå¹¶ä»ä»¥ä¸‹ä¸¤ç§æ“ä½œä¸­é€‰æ‹©ä¸€ç§æ‰§è¡Œï¼š

                  1.  **æ”¹å†™é—®é¢˜**: å¦‚æœç”¨æˆ·çš„æé—®æ¨¡ç³Šã€ä¸å®Œæ•´æˆ–ä¸¥é‡ä¾èµ–ä¸Šä¸‹æ–‡ï¼Œè¯·å°†å…¶æ”¹å†™æˆä¸€ä¸ªç‹¬ç«‹ã€æ¸…æ™°ã€å®Œæ•´çš„ä¸“ä¸šé—®é¢˜ã€‚
                      - æ”¹å†™åçš„é—®é¢˜åº”èå…¥ä¸Šä¸‹æ–‡ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚

                  2.  **æ— éœ€æ”¹å†™**: å¦‚æœç”¨æˆ·çš„æé—®å·²ç»éå¸¸æ¸…æ™°ã€å…·ä½“ã€å®Œæ•´ï¼Œæ— éœ€ä¿®æ”¹ã€‚
                      - åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¿…é¡»è¾“å‡ºå›ºå®šçš„æ ‡å¿—: `NO_REWRITE_NEEDED`ã€‚

                  ## è¾“å…¥
                  - ç”¨æˆ·æé—®: ç”¨æˆ·çš„æœ€æ–°é—®é¢˜ã€‚
                  - ä¸Šä¸‹æ–‡: æ­¤å‰çš„å¯¹è¯å†å²ã€‚

                  ## è¾“å‡ºæ ¼å¼
                  ä½ çš„è¾“å‡º**å¿…é¡»**æ˜¯ä»¥ä¸‹ä¸¤è€…ä¹‹ä¸€ï¼Œä¸åŒ…å«ä»»ä½•å‰ç¼€æˆ–è§£é‡Šï¼š
                  - æ”¹å†™åçš„å®Œæ•´é—®é¢˜
                  - å›ºå®šçš„æ ‡å¿—: `NO_REWRITE_NEEDED`

                  ## åè¯è§£é‡Š
                  {standard_term}

                  ## ç¤ºä¾‹
                  ### ç¤ºä¾‹ 1: æ”¹å†™é—®é¢˜
                  **è¾“å…¥:**
                  - ç”¨æˆ·æé—®: "è¿™ä¸ªè¦æ€ä¹ˆå¤„ç†ï¼Ÿ"
                  - ä¸Šä¸‹æ–‡: (ä¹‹å‰åœ¨è®¨è®ºä¸åˆæ ¼å“)
                  **è¾“å‡º:**
                  ä¸åˆæ ¼å“è¦æ€ä¹ˆå¤„ç†ï¼Ÿ

                  ### ç¤ºä¾‹ 2: æ— éœ€æ”¹å†™
                  **è¾“å…¥:**
                  - ç”¨æˆ·æé—®: "è¯·ä»‹ç»ä¸€ä¸‹ç”Ÿç›Šç§‘æŠ€S1141æ¿æçš„è¯¦ç»†ç”Ÿäº§å·¥è‰ºæµç¨‹ã€‚"
                  - ä¸Šä¸‹æ–‡: (æ— ç›¸å…³ä¸Šä¸‹æ–‡)
                  **è¾“å‡º:**
                  NO_REWRITE_NEEDED
              - type: placeholder
                variable: history3
              - type: human
                template: |-
                  {content}
          sinks:
            logging: true
            context: search_words

        - name: é™åˆ¶å†å²è®°å½•æ¡æ•°
          code: sources.execution
          args:
            locals:
              history: "{context#history}"
              max_turns: "{context#history_turns}"
            source: |-
              from langchain.schema import HumanMessage, AIMessage
              
              # å¦‚æœå†å²è®°å½•è¶…è¿‡æœ€å¤§è½®æ•°ï¼Œåªä¿ç•™æœ€è¿‘çš„å‡ è½®å¯¹è¯
              if isinstance(history, list) and len(history) > max_turns * 2:
                  history = history[-max_turns * 2:]
              
              return history
          sinks:
            context: history5
            logging: true

        - name: è·å–æ„å›¾è¯†åˆ«å†å²è®°å½•
          code: topics.memory.operations#get
          args:
            key: query
          sinks:
            context: query

        - name: è·å–ä¸Šä¸€ä¸ªçŸ¥è¯†åº“å¬å›å†…å®¹
          code: topics.memory.operations#get
          args:
            key: item_snippet_history
          sinks:
            context: item_snippet_history

        - name: å¦‚æœä¸ºç©ºåˆ™åˆå§‹åŒ–ä¸º""
          code: sources.execution
          args:
            source: |-
              query = """{context#query}"""
              if not query or query == """context#query""" or query == None:
                query = ""
              return query
          sinks:
            context: query
            logging: true
        

        - name: å¦‚æœç­‰äºNO_REWRITE_NEEDEDï¼Œåˆ™ç›´æ¥è¿”å›
          code: sources.execution
          args:
            locals:
              search_words: "{context#search_words}"
              content: "{context#question}"
            source: |-
              if search_words == "NO_REWRITE_NEEDED":
                res = content
              else:
                res = search_words
              return res
          sinks:
            context: search_words
            logging: true

        - name: ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
          code: knowledge.hybrid.operations#similar
          args:
            knowledge: "{context#qa_knowledge_id}"
            kwargs:
              query: "{context#content}"
              dialect: "default"
              threshold:
                enabled: true
                value: 0.2
              rerank:
                enabled: true
                model: "gte-rerank"
              top_k: 5
            raw: true
          sinks:
            context: retrieved_documents
            logging: true

        - name: æ„å»ºæ£€ç´¢ç»“æœä¸ºobjectæ ¼å¼ï¼Œä¸€ä¸ªæ˜¯å¤§æ¨¡å‹å¼•ç”¨çš„å­—ç¬¦ä¸²å­—æ®µï¼Œä¸€ä¸ªæ˜¯æ–‡ä»¶å¼•ç”¨çš„å­—æ®µ
          code: sources.execution
          args:
            locals:
              docs: "{context#retrieved_documents}"
            source: |-
              def main(docs):
                if not docs or len(docs) == 0:
                  return {
                    "llm_context": "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£",
                    "references": {
                      "footnotes": 0,
                      "docs": []
                    }
                  }
                
                # æ„å»ºå¤§æ¨¡å‹å¼•ç”¨çš„å­—ç¬¦ä¸²å­—æ®µ
                llm_context_parts = []
                references_docs = []
                
                for i, doc in enumerate(docs):
                  content = doc.page_content if hasattr(doc, 'page_content') else doc.content
                  metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                  
                  # æå–æ ‡é¢˜
                  lines = content.split("\n")
                  title = lines[0].replace("# ", "") if lines and lines[0].startswith("# ") else f"æ–‡æ¡£{i+1}"
                  
                  # æ„å»ºå¤§æ¨¡å‹å¼•ç”¨å­—ç¬¦ä¸²
                  llm_context_parts.append(f"[^{i+1}] {title}: {content}")
                  
                  # æ„å»ºæ–‡ä»¶å¼•ç”¨å¯¹è±¡
                  doc_id = metadata.get("docs", "")
                  ref = {
                    "id": doc_id,
                    "type": "raw",
                    "title": title,
                    "filename": title + ".docx",
                    "directory": None,
                    "link": f"https://apps-dev1.aquaintelling.com/api/de-connect/de001/docs/{doc_id}",
                    "preview_type": "file",
                    "pages": [{
                      "number": 1,
                      "content": content,
                      "fn": i + 1
                    }]
                  }
                  references_docs.append(ref)
                
                return {
                  "llm_context": "\n\n".join(llm_context_parts),
                  "references": {
                    "footnotes": len(references_docs),
                    "docs": references_docs
                  }
                }
              return main(docs)
          sinks:
            context: search_results
            logging: true

        - name: æ„å›¾è¯†åˆ«é‡å»º
          code: llmx.predict.chat
          steps: |-
            { "id": 1, "content": "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..." }
          args:
            llm:
              name: gpt-4o-2024-08-06
              temperature: 0.1
            messages:
              - type: system
                template: |-
                  # Role: æ™ºèƒ½ä¿¡æ¯æºåˆ†æå¸ˆ
                  **æ ¸å¿ƒä»»åŠ¡**  
                  åˆ†æç”¨æˆ·æé—®ï¼Œç²¾å‡†åˆ¤æ–­æ‰€éœ€ä¿¡æ¯æºç±»å‹ï¼ˆ0-Nä¸ªï¼‰ï¼Œç¡®ä¿å›ç­”æƒå¨æ€§ä¸æ—¶æ•ˆæ€§ã€‚

                  ## å¯ç”¨ä¿¡æ¯æºåŠé€‰æ‹©æ ‡å‡†
                  1.  **æœ¬åœ°çŸ¥è¯†åº“ï¼ˆ`local_knowledge`ï¼‰**  
                      ğŸ“Œ *é€‰æ‹©æ—¶æœº*ï¼šå½“"ç›¸ä¼¼é—®ç­”åº“æ£€ç´¢ç»“æœ"ä¸­å­˜åœ¨å¯ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„åŒ¹é…å†…å®¹æ—¶ï¼ˆå¦‚æ”¿ç­–æ³•è§„ã€åŠäº‹æµç¨‹ç­‰æœ¬åœ°åŒ–ä¿¡æ¯ï¼‰ï¼Œå¯ç”¨æ­¤æºã€‚

                  2.  **å®æ—¶ç½‘ç»œæ£€ç´¢ï¼ˆ`realtime_search`ï¼‰**  
                      ğŸ“Œ *é€‰æ‹©æ—¶æœº*ï¼šé—®é¢˜æ¶‰åŠä»¥ä¸‹åœºæ™¯æ—¶å¯ç”¨ï¼š  
                      - è¶…å‡ºç°æœ‰çŸ¥è¯†åº“çš„å®æ—¶ä¿¡æ¯ï¼ˆå¦‚æ–°é—»/èµ›äº‹/è‚¡ä»·ï¼‰  
                      - è·¨é¢†åŸŸé€šç”¨çŸ¥è¯†ï¼ˆå¦‚ç§‘æŠ€è¿›å±•/å†å²äº‹ä»¶ï¼‰  
                      - éœ€éªŒè¯çš„åŠ¨æ€æ•°æ®ï¼ˆå¦‚æœºæ„æœ€æ–°è”ç³»æ–¹å¼ï¼‰

                  3.  **å†å²çŸ¥è¯†æ¨¡å—ï¼ˆ`history_knowledge`ï¼‰**  
                      ğŸ“Œ *é€‰æ‹©æ—¶æœº*ï¼šæ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶æ—¶å¯ç”¨ï¼š  
                      - å¯¹å‰åºå›ç­”çš„è¿½é—®ï¼ˆæ— éœ€æ–°æ•°æ®æºï¼‰

                  ## è¾“å…¥å‚æ•°
                  - **ç›¸ä¼¼é—®ç­”åº“æ£€ç´¢ç»“æœ**:  
                    ```
                    {ragflow_result_qa}
                    ```
                  - ** ä¸Šä¸€ä¸ªæé—®å¬å›çŸ¥è¯†åº“å†…å®¹**:
                    ```
                    {item_snippet_history}
                    ```

                  ## è¾“å‡ºæ ¼å¼
                  ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œ`flag`å­—æ®µæ˜¯ä¸€ä¸ªåŒ…å«é›¶ä¸ªæˆ–å¤šä¸ªä¿¡æ¯æºæ ‡è¯†çš„åˆ—è¡¨ã€‚

                  ```json
                  {{
                    "reasoning": "string",
                    "flag": ["string"]
                  }}
                  ```

                  ## Attention
                  ä½ çš„è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªJSONæ ¼å¼ã€‚`reasoning`å­—æ®µçš„åˆ†æè¿‡ç¨‹è‡³å…³é‡è¦ã€‚
              # - type: placeholder
              #   variable: history5
              - type: human
                template: |-
                  {query}
                  human:{content}
                  {current_district_flag}
            format: 
              type: json_schema
              json_schema:
                name: "qa_intent_rewrite"
                schema:
                  type: object
                  properties:
                    reasoning:
                      type: string
                    flag:
                      type: array
                      items:
                        type: string
                  required:
                    - reasoning
                    - flag
                  additionalProperties: false
                strict: true
            inputs:
              ragflow_result_qa: "{context#ragflow_result_qa.context}"
              llm_context: "{context#search_results.llm_context}"
          sinks:
            format:
              type: load-json-object
            context: refined_query
            logging: true
            
        - name: qaå¬å›ç»“æœæ³¨å…¥åˆ†æ”¯
          code: logics.case
          args:
            - when: "'local_knowledge' in '{context#refined_query.flag}'"
              then: 
                - name: è®¾ç½®qaå¬å›ç»“æœ
                  code: sources.execution
                  args:
                    locals:
                      prompt_ragflow_result_qa_context: "{context#ragflow_result_qa.context}"
                    source: |-
                      prompt_ragflow_result_qa_context = prompt_ragflow_result_qa_context.replace("{", "").replace("}", "")
                      return prompt_ragflow_result_qa_context
                  sinks:
                    context: prompt_ragflow_result_qa_context
                    logging: true
            - else:
                - name: è®¾ç½®qaå¬å›ç»“æœä¸ºç©º
                  code: sources.execution
                  args:
                    source: |-
                      prompt_ragflow_result_qa_context = ""
                      return prompt_ragflow_result_qa_context
                  sinks:
                    context: prompt_ragflow_result_qa_context
                    logging: true
        
        - name: realtime_searchå¬å›ç»“æœæ³¨å…¥åˆ†æ”¯
          code: logics.case
          args:
            - when: "'realtime_search' in '{context#refined_query.flag}' and {context#is_internet_search} == 1"
              then: 
                - name: æ—¥æœŸè·å–
                  code: sources.execution
                  args:
                    source: |-
                      from datetime import datetime, timedelta
                      current_date = datetime.now().date()
                      date_360 = current_date - timedelta(days=360)
                      date_720 = current_date - timedelta(days=720)
                      date_1440 = current_date - timedelta(days=1440) 
                      date_100 = current_date - timedelta(days=100)
                      current_date = current_date.strftime("%Y-%m-%d")
                      date_360 = date_360.strftime("%Y-%m-%d")
                      date_720 = date_720.strftime("%Y-%m-%d")
                      date_1440 = date_1440.strftime("%Y-%m-%d")
                      date_100 = date_100.strftime("%Y-%m-%d")
                      result = {'current_date': current_date, 'date_360': date_360, 'date_720': date_720, 'date_1440': date_1440, 'date_100': date_100}
                      return result
                  sinks:
                    logging: true
                    context: dates

                - name: ç”Ÿæˆè”ç½‘é—®ç­”æœç´¢è¯
                  code: llmx.predict.chat
                  steps: |-
                    { "id": 1, "content": "æ­£åœ¨è”ç½‘æœç´¢ä¸­..." }
                  args:
                    messages:
                      - type: system
                        template: |-
                          # Role
                          bingsearch ç½‘ç»œæœç´¢ä¸“å®¶

                          ## Goal
                          è®¾è®¡å¹¶æ„å»ºåˆé€‚çš„æœç´¢è¯ï¼Œæœç´¢æ•°é‡ï¼Œæœç´¢æ—¶é—´èŒƒå›´ï¼Œä»¥è·å–æœ€å‡†ç¡®ã€æœ€å…¨é¢çš„æœç´¢ç»“æœ  

                          ## Skills
                          ä»¥ä¸‹æ˜¯æœ€å¸¸ç”¨ã€ç®€å•é«˜æ•ˆçš„ç½‘ç»œæœç´¢æŠ€å·§ï¼š

                          ### 1. ç²¾å‡†å…³é”®è¯  
                          ç›´æ¥ä½¿ç”¨æ ¸å¿ƒå…³é”®è¯ï¼Œé¿å…é•¿å¥å­æˆ–é—®å¥ã€‚  
                          ä¾‹å¦‚ï¼šç”µè„‘å¡é¡¿è§£å†³åŠæ³•

                          ### 2. ä½¿ç”¨å¼•å· ("")  
                          ç²¾ç¡®åŒ¹é…çŸ­è¯­æˆ–å›ºå®šè¡¨è¾¾ã€‚  
                          ä¾‹å¦‚ï¼š"äººå·¥æ™ºèƒ½çš„æœªæ¥"

                          ### 3. ä½¿ç”¨å‡å· (-)  
                          æ’é™¤ä¸ç›¸å…³å†…å®¹ã€‚  
                          ä¾‹å¦‚ï¼šPython æ•™ç¨‹ -è›‡

                          ### 4. ç«™ç‚¹æœç´¢ (site:)  
                          é™å®šåœ¨ç‰¹å®šç½‘ç«™æœç´¢ã€‚  
                          ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½ site:baidu.com

                          ## Example
                          input: "æ·±åœ³è¿™ä¸¤å¹´çš„ç»æµè¿è¡Œæƒ…å†µæ€ä¹ˆæ ·ï¼Ÿ"
                          output:
                          [{{
                            "query": "æ·±åœ³ ç»æµè¿è¡Œ æœ€æ–°",
                            "count": 10,
                            "freshness": "{context#dates.date_720}..{context#dates.current_date}"
                          }}]
                          input: "ä¸­å›½å’Œéæ´²å›½å®¶æœ€è¿‘çš„å¤–äº¤å…³ç³»å¦‚ä½•ï¼Ÿ"
                          output:
                          [{{
                            "query": "ä¸­å›½ éæ´² å¤–äº¤å…³ç³» æœ€æ–°",
                            "count": 10,
                            "freshness": "{context#dates.date_100}..{context#dates.current_date}"
                          }}]
                          input: "åˆåˆ›èèµ„éœ€è¦å¼„æ˜ç™½çš„é—®é¢˜ï¼Ÿ"
                          output:
                          [{{
                            "query": "åˆåˆ›èèµ„å¸¸è§çš„è¯¯åŒºä¸æ³¨æ„äº‹é¡¹",
                            "count": 3,
                            "freshness": ""
                          }},
                          {{
                            "query": "åˆåˆ›ä¼ä¸šèèµ„åŸºæœ¬æµç¨‹",
                            "count": 3,
                            "freshness": ""
                          }},
                          {{
                            "query": "2024å¹´åˆåˆ›ä¼ä¸šèèµ„è¶‹åŠ¿",
                            "count": 3,
                            "freshness": ""
                          }},
                          {{
                            "query": "åˆåˆ›èèµ„éœ€è¦å¼„æ˜ç™½çš„é—®é¢˜",
                            "count": 3,
                            "freshness": ""
                          }}]

                          ## å­—æ®µè§£é‡Š
                          - query: æœç´¢è¯
                          - count: æœç´¢æ•°é‡
                          - freshness: æœç´¢æ—¶é—´èŒƒå›´ï¼Œå¯ä»¥ä¸ºç©ºè¡¨ç¤ºä¸é™åˆ¶

                          ## Rules
                          1. å•æ¡å…³é”®è¯æœç´¢é»˜è®¤æœç´¢æ•°é‡ä¸º5-10æ¡ï¼Œç®€å•é—®é¢˜å¯æœç´¢3-5æ¡
                          2. æœç´¢æ—¶é—´èŒƒå›´é»˜è®¤ä¸ºç©ºï¼Œé™¤éæ˜ç¡®è¡¨ç¤ºæ—¶é—´ï¼Œeg: æœ€è¿‘ä¸€å¹´ï¼Œåˆ™æœç´¢æ—¶é—´èŒƒå›´ä¸ºä¸€å¹´
                          3. ä¸€èˆ¬é—®é¢˜ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨å¯¹è±¡å³å¯ï¼Œå¤æ‚é—®é¢˜åˆ™å¯è¿”å›å¤šä¸ªæœç´¢å…³é”®è¯
                          4. å¤šæ¡æœç´¢æ—¶æœç´¢æ€»æ•°ä¸è¶…è¿‡12æ¡ï¼

                          ## OutputFormat
                          Array of objects

                          ## Constrains:
                          ä»Šå¤©æ—¶é—´æ˜¯{context#dates.current_date}
                      - type: human
                        template: |-
                          åŸå§‹æé—®ï¼š{content}
                          ä¿®æ­£åçš„æé—®ï¼š{search_words}
                    inputs:
                      content: "{context#question}"
                      search_words: "{context#search_words}"
                  sinks:
                    format:
                      type: load-json-object
                    context: search_query
                    logging: true
                
                - name: é»˜è®¤å€¼
                  code: sources.execution
                  args:
                    source: |-
                      def process_search_query(query_obj):
                          # é»˜è®¤å€¼
                          default_query = [{
                              "query": "{context#question}",
                              "count": 10,
                              "freshness": f"{context#dates.date_720}..{context#dates.current_date}"
                          }]
                          
                          try:
                              # å¤„ç†Noneæˆ–ç©ºå€¼æƒ…å†µ
                              if not query_obj:
                                  return default_query
                              
                              # å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                              if isinstance(query_obj, str):
                                  try:
                                      import json
                                      query_obj = json.loads(query_obj)
                                  except:
                                      return default_query
                              
                              # å¦‚æœæ˜¯å•ä¸ªæŸ¥è¯¢å¯¹è±¡ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                              if isinstance(query_obj, dict):
                                  query_obj = [query_obj]
                              
                              # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨æ ¼å¼
                              if isinstance(query_obj, list):
                                  result = []
                                  for item in query_obj:
                                      # å¤„ç†æ¯ä¸ªæŸ¥è¯¢å¯¹è±¡
                                      if isinstance(item, dict):
                                          query = item.get("query", "")
                                          count = item.get("count", 10)
                                          freshness = item.get("freshness", "")
                                          
                                          # å¦‚æœqueryæ˜¯contextå ä½ç¬¦ï¼Œä½¿ç”¨content
                                          if str(query).startswith("context#"):
                                              query = "{context#question}"
                                          
                                          # å¦‚æœfreshnessæ˜¯contextå ä½ç¬¦æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼
                                          if not freshness or str(freshness).startswith("context#"):
                                              freshness = f"{context#dates.date_720}..{context#dates.current_date}"
                                          
                                          result.append({
                                              "query": query,
                                              "count": count,
                                              "freshness": freshness
                                          })
                                  return result if result else default_query
                              
                              # å…¶ä»–æƒ…å†µè¿”å›é»˜è®¤å€¼
                              return default_query
                              
                          except Exception as e:
                              print(f"Error processing search query: {str(e)}")
                              return default_query
                      
                      # è·å–å¹¶å¤„ç†æœç´¢æŸ¥è¯¢
                      search_query = {context#search_query}
                      result = process_search_query(search_query)
                      
                      # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼
                      if not isinstance(result, list):
                          result = [result] if result else [{
                              "query": "{context#question}",
                              "count": 10,
                              "freshness": f"{context#dates.date_720}..{context#dates.current_date}"
                          }]
                      
                      return result
                  sinks:
                    context: search_query
                    logging: true

                - name: å¾ªç¯å¤„ç†æœç´¢è¯
                  code: logics.loop
                  args:
                    iterable: "{context#search_query}"
                    threads: 3
                    consumer:
                      - name: æœç´¢å›½å®¶ä¿¡æ¯
                        code: internets.search.bing
                        # steps: |-
                        #   { "id": 1, "content": "==>>>æ­£åœ¨è”ç½‘æœç´¢ä¸­...==>>>" }
                        args:
                          timeout: 10
                          keywords: "{context#x.query}"
                          freshness: "{context#x.freshness}"
                          scope: full
                          limit: "{context#x.count}"
                        sinks:
                          context: 
                            scope: origin
                            type: extend-props
                            name: web_search_result_list
                          logging: true

                - name: æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¤§æ¨¡å‹è¾“å…¥
                  code: sources.execution
                  args:
                    source: |-
                      def format_for_llm(web_search_result):
                          try:
                              # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºåˆ—è¡¨ä¸”éç©º
                              if not isinstance(web_search_result, list):
                                  print(f"é¢„æœŸåˆ—è¡¨ç±»å‹ï¼Œä½†è·å¾—äº† {type(web_search_result)}")
                                  return {"context": "", "references": {"webs": [], "footnotes": 0}}
                              
                              if not web_search_result:
                                  print("æœç´¢ç»“æœåˆ—è¡¨ä¸ºç©º")
                                  return {"context": "", "references": {"webs": [], "footnotes": 0}}
                              
                              context_parts = []
                              references = {"webs": [], "footnotes": 0}
                              
                              for idx, result in enumerate(web_search_result, 1):
                                  try:
                                      # è·å–æ ‡é¢˜å’Œå†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨snippetå­—æ®µ
                                      title = result.get("title", "")
                                      content = result.get("snippet", result.get("content", ""))
                                      link = result.get("link", "")
                                      
                                      # è·³è¿‡æ²¡æœ‰æœ‰æ•ˆå†…å®¹çš„ç»“æœ
                                      if not title and not content:
                                          print(f"è·³è¿‡ç´¢å¼• {idx} å¤„çš„ç©ºç»“æœ")
                                          continue
                                      
                                      # æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†
                                      context_parts.extend([
                                          f"[^{idx}]{title}",
                                          "=====",
                                          content,
                                          "====="
                                      ])
                                      
                                      # æ„å»ºå¼•ç”¨éƒ¨åˆ†
                                      ref_entry = {
                                          "title": title,
                                          "link": link,
                                          "snippet": content,
                                          "fn": idx,
                                      }
                                      references["webs"].append(ref_entry)
                                      
                                  except Exception as e:
                                      print(f"å¤„ç†ç»“æœ {idx} æ—¶å‡ºé”™: {str(e)}")
                                      continue
                              
                              references["footnotes"] = len(references["webs"])
                              
                              result = {
                                  "context": "\n".join(context_parts),
                                  "references": references
                              }
                              
                              return result
                          except Exception as e:
                              print(f"format_for_llm å‡½æ•°å‡ºé”™: {str(e)}")
                              return {"context": "", "references": {"webs": [], "footnotes": 0}}

                      # è·å–æœç´¢ç»“æœå¹¶æ ¼å¼åŒ–
                      web_search_result = {context#web_search_result_list}
                      result = format_for_llm(web_search_result)
                      
                      return result
                  sinks:
                    context: web_search_result_clean
                    logging: true

        - name: history_knowledge promptæ³¨å…¥åˆ†æ”¯
          code: logics.case
          args:
            - when: "'history_knowledge' in '{context#refined_query.flag}'"
              then:
   
                - name: è®¾ç½®å†å²çŸ¥è¯†
                  code: sources.execution
                  args:
                    locals:
                      prompt_item_snippet_history: "{context#item_snippet_history}"
                    source: |-
                      prompt_item_snippet_history = prompt_item_snippet_history.replace("{", "").replace("}", "")
                      return prompt_item_snippet_history
                  sinks:
                    context: prompt_item_snippet_history
                    logging: true
            - else:
                - name: è®¾ç½®å†å²çŸ¥è¯†
                  code: sources.execution
                  args:
                    source: |-
                      prompt_item_snippet_history = ""
                      return prompt_item_snippet_history
                  sinks:
                    context: prompt_item_snippet_history
                    logging: true

        - name: ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
          code: knowledge.hybrid.operations#similar
          args:
            knowledge: "{context#qa_knowledge_id}"
            kwargs:
              query: "{context#content}"
              dialect: "default"
              threshold:
                enabled: true
                value: 0.2
              rerank:
                enabled: true
                model: "gte-rerank"
              top_k: 5
            raw: true
          sinks:
            context: retrieved_documents
            logging: true


        - name: åˆå¹¶æœç´¢ç»“æœ
          code: sources.execution
          args:
            locals:
              refined_query_flag: "{context#refined_query.flag}"
              ragflow_result: "{context#ragflow_result}"
              web_search_result_clean: "{context#web_search_result_clean}"
            source: |-
              # åˆå§‹åŒ–ç»“æœ
              combined_context_parts = []
              combined_references = {"webs": [], "footnotes": 0}
              current_fn = 1
              
              # å¤„ç†ragflowç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
              if ragflow_result and ragflow_result.get("llm_context"):
                  ragflow_context = ragflow_result.get("llm_context", "")
                  ragflow_refs = ragflow_result.get("references", {}).get("docs", [])
                  
                  if ragflow_context:
                      # é‡æ–°ç¼–å·ragflowçš„ä¸Šä¸‹æ–‡å¼•ç”¨
                      import re
                      def update_ragflow_reference_numbers(text, start_num):
                          def replace_ref(match):
                              return f"[^{start_num + int(match.group(1)) - 1}]"
                          return re.sub(r'\[\^(\d+)\]', replace_ref, text)
                      
                      updated_ragflow_context = update_ragflow_reference_numbers(ragflow_context, current_fn)
                      combined_context_parts.append(updated_ragflow_context)
                      
                  # æ·»åŠ ragflowå¼•ç”¨ï¼Œè½¬æ¢ä¸ºwebsæ ¼å¼å¹¶æ›´æ–°ç¼–å·
                  for ref in ragflow_refs:
                      # ä»docsæ ¼å¼è½¬æ¢ä¸ºwebsæ ¼å¼ï¼Œä¿ç•™å®Œæ•´å­—æ®µä¿¡æ¯
                      pages = ref.get("pages", [])
                      if pages:
                          page = pages[0]
                          web_ref = {
                              "id": ref.get("id", ""),
                              "type": ref.get("type", "raw"),
                              "title": ref.get("title", "æœªå‘½åæ–‡æ¡£"),
                              "filename": ref.get("filename", ""),
                              "directory": ref.get("directory"),
                              "link": ref.get("link", ""),
                              "preview_type": ref.get("preview_type", "file"),
                              "snippet": page.get("content", "")[:500],
                              "fn": current_fn,
                              "pages": [{
                                  "number": page.get("number", 1),
                                  "content": page.get("content", ""),
                                  "fn": current_fn
                              }]
                          }
                          combined_references["webs"].append(web_ref)
                          current_fn += 1
              
              # å¤„ç†ç½‘ç»œæœç´¢ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
              if "realtime_search" in refined_query_flag and web_search_result_clean and web_search_result_clean.get("context"):
                  web_context = web_search_result_clean.get("context", "")
                  web_refs = web_search_result_clean.get("references", {}).get("webs", [])
                  
                  if web_context:
                      # é‡æ–°ç¼–å·ç½‘ç»œæœç´¢ç»“æœçš„ä¸Šä¸‹æ–‡
                      import re
                      def update_reference_numbers(text, start_num):
                          def replace_ref(match):
                              return f"[^{start_num + int(match.group(1)) - 1}]"
                          return re.sub(r'\[\^(\d+)\]', replace_ref, text)
                      
                      updated_web_context = update_reference_numbers(web_context, current_fn)
                      combined_context_parts.append(updated_web_context)
                      
                  # æ·»åŠ ç½‘ç»œæœç´¢å¼•ç”¨ï¼Œæ›´æ–°ç¼–å·
                  for ref in web_refs:
                      ref_copy = ref.copy()
                      ref_copy["fn"] = current_fn
                      combined_references["webs"].append(ref_copy)
                      current_fn += 1
              
              # æ›´æ–°footnotesè®¡æ•°
              combined_references["footnotes"] = len(combined_references["webs"])
              
              # ç»„åˆæœ€ç»ˆç»“æœ
              final_result = {
                  "context": "\n".join(combined_context_parts),
                  "references": combined_references
              }
              
              return final_result
          sinks:
            context: final_search_result
            logging: true

        - name: åˆ¤æ–­æ˜¯å¦ä¸º0
          code: logics.case
          args:
            - when: "{context#ragflow_result.references.footnotes} == 0"
              then:
                - name: å›ç­”é—®é¢˜
                  code: reply.operations
                  args:
                    pending: "æŠ±æ­‰ï¼Œç›®å‰æ²¡æœ‰è¿™æ–¹é¢çš„ç›¸å…³ä¿¡æ¯å‘¢~"
            
            - else:
                - name: å¤§æ¨¡å‹å›ç­”  
                  code: llmx.predict.chat
                  steps: |-
                    { "id": 1, "content": "æ­£åœ¨åŠªåŠ›å›ç­”æ‚¨çš„é—®é¢˜..." }
                  args:
                    # llm:
                    #   name: qwen-plus
                    messages:
                      - type: system
                        template: |-
                          {role_prompt}

                          ## çŸ¥è¯†åº“
                          {final_search_result}

                          ## å†å²çŸ¥è¯†
                          {prompt_item_snippet_history}

                          ## ç›¸ä¼¼é—®ç­”åº“
                          {prompt_ragflow_result_qa_context}

                          ## Attention
                          - ä½¿ç”¨[^x]æ ¼å¼æ¥å¼•ç”¨çŸ¥è¯†åº“ä¸­çš„å†…å®¹ï¼Œxä¸ºå¼•ç”¨å†…å®¹çš„ç¼–å·ã€‚
                          - æ²¡æœ‰ç›¸å…³ä¿¡æ¯æ—¶ï¼Œè¯·å›ç­”ï¼šæŠ±æ­‰ï¼Œç›®å‰æ²¡æœ‰è¿™æ–¹é¢çš„ç›¸å…³ä¿¡æ¯å‘¢~
                      - type: placeholder
                        variable: history5
                      - type: human
                        template: |-
                          {content}
                    reply: pending
                    inputs:
                      final_search_result: "{context#final_search_result.context}"
                  sinks:
                    logging: true
                    context: llm_answer2

                - name: åˆ¤æ–­å›ç­”æ˜¯å¦ä¸ºæŠ±æ­‰ï¼Œç›®å‰æ²¡æœ‰è¿™æ–¹é¢çš„ç›¸å…³ä¿¡æ¯å‘¢~
                  code: sources.execution
                  args:
                    source: |-
                      if """æŠ±æ­‰ï¼Œç›®å‰æ²¡æœ‰è¿™æ–¹é¢çš„ç›¸å…³ä¿¡æ¯å‘¢~""" in """{context#llm_answer}""":
                        res = 1
                      else:
                        res = 0
                      return res
                  sinks:
                    context: rec_flag
                    logging: true

                - name: è®°å½•æ•°æ®
                  code: logics.case
                  args:
                    - when: "{context#rec_flag} == 1"
                      then:
                        - name: åˆ›å»ºè¡¨æ ¼(å¦‚æœä¸å­˜åœ¨)
                          code: mysql.operations#execute
                          args:
                            statement: |-
                              CREATE TABLE IF NOT EXISTS unanswered_questions (
                                id VARCHAR(32),
                                category VARCHAR(32),
                                question VARCHAR(5000),
                                updated_at VARCHAR(32)
                              );
                          sinks:
                            logging: true
                            
                        - code: table.operations#insert
                          name: mysqlæ•°æ®æ’å…¥
                          args:
                            tbl: 
                              name: unanswered_questions
                              columns:                      
                                - name: id
                                  type: VARCHAR(32)
                                - name: category
                                  type: VARCHAR(32)
                                - name: question
                                  type: VARCHAR(5000)
                                - name: updated_at
                                  type: VARCHAR(32)
                            rows:
                              - id: '{context#visitor_id}'
                                category: '{context#bot_name}'
                                question: '{context#question}'
                                updated_at: '{context#now}'

- name: åˆ¤æ–­æ˜¯å¦å¼•ç”¨çŸ¥è¯†åº“
  code: sources.execution
  args:
    locals:
      llm_answer: "{context#llm_answer2}"
    source: |-
      # å‡è®¾å¼•ç”¨æ ‡è®°æ€»æ˜¯ä»¥[^å¼€å¤´åŠ æ•°å­—å’Œ]ç»“å°¾
      res = 0
      for i in range(1, 11):
        if f"[^{i}]" in llm_answer:
          res = 1
          break
      return res
  sinks:
    context: is_reference
    logging: true

- name: æœ‰å¼•ç”¨åˆ™æ ¼å¼åŒ–å¼•ç”¨
  code: logics.case
  args:
    - when: "{context#is_reference} == 1"
      then:
        - name: ç»Ÿä¸€æ ¼å¼åŒ–å¼•ç”¨
          code: sources.execution
          args:
            locals:
              llm_answer: "{context#llm_answer2}"
              final_search_result: "{context#final_search_result}"
            source: |-
              import json
              import re

              # Extract cited reference numbers (e.g., from "[^1]") into a set for efficient lookup.
              # Using `llm_answer or ""` handles potential None values gracefully.
              try:
                  used_indices = set(map(int, re.findall(r'\[\^(\d+)\]', llm_answer or '')))
              except (ValueError, TypeError):
                  used_indices = set()

              # Safely and concisely extract the list of all reference candidates.
              all_references = final_search_result.get("references", {}).get("webs", [])

              # Filter references to keep only those cited, ensuring data integrity.
              cited_webs = [
                  ref for ref in all_references
                  if isinstance(ref, dict) and ref.get("fn") in used_indices
              ] if isinstance(all_references, list) else []

              # Build the final JSON result.
              result = {"webs": cited_webs, "footnotes": len(cited_webs)}

              return json.dumps(result, ensure_ascii=False)
          sinks:
            reply: links
            context: linkReference
            logging: true

- name: æ„å»ºä¸Šä¸‹æ–‡
  code: sources.execution
  args:
    source: |-
      # è·å–å½“å‰queryä¸­çš„å†å²å¯¹è¯
      query = """{context#query}"""
      
      # å°†å†å²è®°å½•æŒ‰å¯¹è¯è½®æ¬¡åˆ†å‰²
      dialog_pairs = []
      current_pair = []
      
      # æŒ‰è¡Œåˆ†å‰²å¹¶è§£æhuman/aiå¯¹è¯
      lines = query.strip().split('\n')
      for line in lines:
          line = line.strip()
          if line.startswith('human:'):
              if current_pair and len(current_pair) == 2:
                  dialog_pairs.append(current_pair)
                  current_pair = []
              current_pair = [line]
          elif line.startswith('ai:') and current_pair:
              current_pair.append(line)
              
      # æ·»åŠ æœ€åä¸€ç»„å¯¹è¯
      if current_pair and len(current_pair) == 2:
          dialog_pairs.append(current_pair)
      
      # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
      if len(dialog_pairs) > 5:
          dialog_pairs = dialog_pairs[-5:]
      
      # æ·»åŠ å½“å‰æ–°çš„å¯¹è¯
      current_content = """{context#question}"""
      current_answer = """{context#llm_answer2}"""
      dialog_pairs.append([f"human:{current_content}", f"ai:{current_answer}"])
      
      # é‡æ–°ç»„è£…å¯¹è¯å†å²
      formatted_dialog = []
      for pair in dialog_pairs:
          formatted_dialog.extend(pair)
      
      return "\n".join(formatted_dialog)
  sinks:
    context: query
    logging: true

- name: ä¿å­˜query
  code: topics.memory.operations#put
  args:
    key: query
    value: "{context#query}"
  sinks:
    logging: true

- name: æ˜¯å¦éœ€è¦æ‹“å±•é—®ç­”
  code: logics.case
  args:
    - when: "{context#extra_question} == 1"
      then:
        - name: æ‰©å±•é—®ç­”
          code: llmx.predict.chat
          args:
            llm:
              model: gpt-4o-mini
              temperature: 0.7
            messages:
              - type: system
                template: |-
                  # Task
                  é¢„åˆ¤ç”¨æˆ·ä¸‹ä¸€æ­¥å¯èƒ½çš„æé—®å†…å®¹ï¼Œç¬¬ä¸€ä¸ªé—®é¢˜å°½é‡å¯ä»å‚è€ƒèµ„æ–™ä¸­å›ç­”

                  # ç”Ÿæˆè§’åº¦
                  1. ä¸åŒç†è®ºè§†è§’
                  2. æ•°æ®é©±åŠ¨çš„æ´å¯Ÿ
                  3. è¡Œä¸ºæ¨¡å¼åˆ†æ
                  4. æƒ…æ„Ÿä¸åŠ¨æœºæ¢è®¨
                  5. é•¿æœŸè¶‹åŠ¿ä¸é¢„æµ‹

                  # æ€è€ƒæ–¹æ³•è®º
                  1. å½’çº³æ³•ä¸æ¼”ç»æ³•ç»“åˆ
                  2. SWOTåˆ†æï¼ˆä¼˜åŠ¿ã€åŠ£åŠ¿ã€æœºä¼šã€å¨èƒï¼‰
                  3. å› æœå…³ç³»é“¾åˆ†æ
                  4. å¤šå˜é‡äº¤å‰åˆ†æ
                  5. å‡è®¾æ£€éªŒä¸éªŒè¯
                  6. é—®é¢˜æ·±åº¦é€’è¿›

                  # ç­”å¤è¦æ±‚
                  1. è¯·å‚è€ƒ[ç°æœ‰æé—®]å’Œ[ç°æœ‰ç­”æ¡ˆ]æ‰©å±•åŠå»¶ä¼¸ 3 æ¡ç›¸å…³çš„æé—®åˆ—è¡¨ã€‚
                  2. ç¦æ­¢æ·»åŠ ä»»ä½•å½¢å¼çš„æ³¨é‡Šã€‚ 
                  3. è¯·ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼è¿›è¡Œç­”å¤ï¼Œä»…éœ€ç­”å¤ JSON æ ¼å¼å†…å®¹(ç¦æ­¢ä½¿ç”¨"```"åŒ…è£¹ç­”æ¡ˆï¼Œç¦æ­¢æ·»åŠ æ³¨é‡Š):
                  {{
                    "question1": string, // ç›¸å…³æé—®1çš„æè¿°
                    "question2": string, // ç›¸å…³æé—®2çš„æè¿°
                    "question3": string // ç›¸å…³æé—®3çš„æè¿°
                  }}
              - type: placeholder
                variable: history5
              - type: human
                template: |-
                  {content}
          sinks:
            format:
              - type: load-json-object
              - type: list-dict-values
              - type: text-joining
                delimiter: "\n"
                pattern: "- {x}"
            reply: extends

- code: refs.operations
  name: ä¿å­˜å†å²è®°å½•
  args:
    flows: chat-memories-flush.yml